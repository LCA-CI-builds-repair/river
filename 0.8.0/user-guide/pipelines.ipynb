{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines are an integral part of river. We encourage their usage and apply them in many of their examples.\n",
    "\n",
    "The `compose.Pipeline` contains all the logic for building and applying pipelines. A pipeline is essentially a list of estimators that are applied in sequence. The only requirement is that the first `n - 1` steps be transformers. The last step can be a regressor, a classifier, a clusterer, a transformer, etc. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-30T18:51:08.558370Z",
     "iopub.status.busy": "2021-08-30T18:51:08.557705Z",
     "iopub.status.idle": "2021-08-30T18:51:10.528103Z",
     "shell.execute_reply": "2021-08-30T18:51:10.527489Z"
    }
   },
   "outputs": [],
   "source": [
    "from river import compose\n",
    "from river import linear_model\n",
    "from river import preprocessing\n",
    "from river import feature_extraction\n",
    "\n",
    "model = compose.Pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    feature_extraction.PolynomialExtender(),\n",
    "    linear_model.LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the `|` operator, as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-30T18:51:10.532522Z",
     "iopub.status.busy": "2021-08-30T18:51:10.531991Z",
     "iopub.status.idle": "2021-08-30T18:51:10.535421Z",
     "shell.execute_reply": "2021-08-30T18:51:10.534998Z"
    }
   },
   "outputs": [],
   "source": [
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    feature_extraction.PolynomialExtender() |\n",
    "    linear_model.LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, equally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-30T18:51:10.540346Z",
     "iopub.status.busy": "2021-08-30T18:51:10.539153Z",
     "iopub.status.idle": "2021-08-30T18:51:10.540981Z",
     "shell.execute_reply": "2021-08-30T18:51:10.541440Z"
    }
   },
   "outputs": [],
   "source": [
    "model = preprocessing.StandardScaler() \n",
    "model |= feature_extraction.PolynomialExtender()\n",
    "model |= linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pipeline has a `draw` method that can be used to visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-30T18:51:10.547538Z",
     "iopub.status.busy": "2021-08-30T18:51:10.547029Z",
     "iopub.status.idle": "2021-08-30T18:51:10.552984Z",
     "shell.execute_reply": "2021-08-30T18:51:10.553413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><div class=\"pipeline\"><details class=\"estimator\"><summary><pre class=\"estimator-name\">StandardScaler</pre></summary><code class=\"estimator-params\">\n",
       "{'counts': Counter(),\n",
       " 'means': defaultdict(&lt;class 'float'&gt;, {}),\n",
       " 'vars': defaultdict(&lt;class 'float'&gt;, {}),\n",
       " 'with_std': True}\n",
       "\n",
       "</code></details><details class=\"estimator\"><summary><pre class=\"estimator-name\">PolynomialExtender</pre></summary><code class=\"estimator-params\">\n",
       "{'bias_name': 'bias',\n",
       " 'degree': 2,\n",
       " 'include_bias': False,\n",
       " 'interaction_only': False}\n",
       "\n",
       "</code></details><details class=\"estimator\"><summary><pre class=\"estimator-name\">LinearRegression</pre></summary><code class=\"estimator-params\">\n",
       "{'_weights': {},\n",
       " '_y_name': None,\n",
       " 'clip_gradient': 1000000000000.0,\n",
       " 'initializer': Zeros (),\n",
       " 'intercept': 0.0,\n",
       " 'intercept_init': 0.0,\n",
       " 'intercept_lr': Constant({'learning_rate': 0.01}),\n",
       " 'l2': 0.0,\n",
       " 'loss': Squared({}),\n",
       " 'optimizer': SGD({'lr': Constant({'learning_rate': 0.01}), 'n_iterations': 0})}\n",
       "\n",
       "</code></details></div></body><style>\n",
       ".estimator {\n",
       "    padding: 1em;\n",
       "    border-style: solid;\n",
       "    background: white;\n",
       "}\n",
       "\n",
       ".pipeline {\n",
       "    display: flex;\n",
       "    flex-direction: column;\n",
       "    align-items: center;\n",
       "    background: linear-gradient(#000, #000) no-repeat center / 3px 100%;\n",
       "}\n",
       "\n",
       ".union {\n",
       "    display: flex;\n",
       "    flex-direction: row;\n",
       "    align-items: center;\n",
       "    justify-content: center;\n",
       "    padding: 1em;\n",
       "    border-style: solid;\n",
       "    background: white\n",
       "}\n",
       "\n",
       "/* Vertical spacing between steps */\n",
       "\n",
       ".estimator + .estimator,\n",
       ".estimator + .union,\n",
       ".union + .estimator {\n",
       "    margin-top: 2em;\n",
       "}\n",
       "\n",
       ".union > .estimator {\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       "/* Spacing within a union of estimators */\n",
       "\n",
       ".union >\n",
       ".estimator + .estimator,\n",
       ".pipeline + .estimator,\n",
       ".estimator + .pipeline,\n",
       ".pipeline + .pipeline {\n",
       "    margin-left: 1em;\n",
       "}\n",
       "\n",
       "/* Typography */\n",
       ".estimator-params {\n",
       "    display: block;\n",
       "    white-space: pre-wrap;\n",
       "    font-size: 120%;\n",
       "    margin-bottom: -1em;\n",
       "}\n",
       "\n",
       ".estimator > code {\n",
       "    background-color: white !important;\n",
       "}\n",
       "\n",
       ".estimator-name {\n",
       "    display: inline;\n",
       "    margin: 0;\n",
       "    font-size: 130%;\n",
       "}\n",
       "\n",
       "/* Toggle */\n",
       "\n",
       "summary {\n",
       "    display: flex;\n",
       "    align-items:center;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       "summary > div {\n",
       "    width: 100%;\n",
       "}\n",
       "</style></html>"
      ],
      "text/plain": [
       "Pipeline (\n",
       "  StandardScaler (\n",
       "    with_std=True\n",
       "  ),\n",
       "  PolynomialExtender (\n",
       "    degree=2\n",
       "    interaction_only=False\n",
       "    include_bias=False\n",
       "    bias_name=\"bias\"\n",
       "  ),\n",
       "  LinearRegression (\n",
       "    optimizer=SGD (\n",
       "      lr=Constant (\n",
       "        learning_rate=0.01\n",
       "      )\n",
       "    )\n",
       "    loss=Squared ()\n",
       "    l2=0.\n",
       "    intercept_init=0.\n",
       "    intercept_lr=Constant (\n",
       "      learning_rate=0.01\n",
       "    )\n",
       "    clip_gradient=1e+12\n",
       "    initializer=Zeros ()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`compose.Pipeline` inherits from `base.Estimator`, which means that it has a `learn_one` method. You would expect `learn_one` to update each estimator, but **that's not actually what happens**. Instead, the transformers are updated when `predict_one` (or `predict_proba_one` for that matter) is called. Indeed, in online machine learning, we can update the unsupervised parts of our model when a sample arrives. We don't have to wait for the ground truth to arrive in order to update unsupervised estimators that don't depend on it. In other words, in a pipeline, `learn_one` updates the supervised parts, whilst `predict_one` updates the unsupervised parts. It's important to be aware of this behavior, as it is quite different to what is done in other libraries that rely on batch machine learning.\n",
    "\n",
    "Here is a small example to illustrate the previous point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-30T18:51:10.557383Z",
     "iopub.status.busy": "2021-08-30T18:51:10.556781Z",
     "iopub.status.idle": "2021-08-30T18:51:10.561765Z",
     "shell.execute_reply": "2021-08-30T18:51:10.561243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ordinal_date': 736389,\n",
       "  'gallup': 43.843213,\n",
       "  'ipsos': 46.19925042857143,\n",
       "  'morning_consult': 48.318749,\n",
       "  'rasmussen': 44.104692,\n",
       "  'you_gov': 43.636914000000004},\n",
       " 43.75505)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import datasets\n",
    "\n",
    "dataset = datasets.TrumpApproval()\n",
    "x, y = next(iter(dataset))\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us call `predict_one`, which will update each transformer, but won't update the linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-30T18:51:10.566585Z",
     "iopub.status.busy": "2021-08-30T18:51:10.566067Z",
     "iopub.status.idle": "2021-08-30T18:51:10.568697Z",
     "shell.execute_reply": "2021-08-30T18:51:10.569261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_one(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction is nil because each weight of the linear regression is equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-30T18:51:10.574445Z",
     "iopub.status.busy": "2021-08-30T18:51:10.573929Z",
     "iopub.status.idle": "2021-08-30T18:51:10.576356Z",
     "shell.execute_reply": "2021-08-30T18:51:10.576804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'ordinal_date': 736389.0,\n",
       "             'gallup': 43.843213,\n",
       "             'ipsos': 46.19925042857143,\n",
       "             'morning_consult': 48.318749,\n",
       "             'rasmussen': 44.104692,\n",
       "             'you_gov': 43.636914000000004})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['StandardScaler'].means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the means of each feature have been updated, even though we called `predict_one` and not `learn_one`.\n",
    "\n",
    "Note that if you call `transform_one` with a pipeline who's last step is not a transformer, then the output from the last transformer (which is thus the penultimate step) will be returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-30T18:51:10.581223Z",
     "iopub.status.busy": "2021-08-30T18:51:10.580703Z",
     "iopub.status.idle": "2021-08-30T18:51:10.583344Z",
     "shell.execute_reply": "2021-08-30T18:51:10.583743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ordinal_date': 0.0,\n",
       " 'gallup': 0.0,\n",
       " 'ipsos': 0.0,\n",
       " 'morning_consult': 0.0,\n",
       " 'rasmussen': 0.0,\n",
       " 'you_gov': 0.0,\n",
       " 'ordinal_date*ordinal_date': 0.0,\n",
       " 'gallup*ordinal_date': 0.0,\n",
       " 'ipsos*ordinal_date': 0.0,\n",
       " 'morning_consult*ordinal_date': 0.0,\n",
       " 'ordinal_date*rasmussen': 0.0,\n",
       " 'ordinal_date*you_gov': 0.0,\n",
       " 'gallup*gallup': 0.0,\n",
       " 'gallup*ipsos': 0.0,\n",
       " 'gallup*morning_consult': 0.0,\n",
       " 'gallup*rasmussen': 0.0,\n",
       " 'gallup*you_gov': 0.0,\n",
       " 'ipsos*ipsos': 0.0,\n",
       " 'ipsos*morning_consult': 0.0,\n",
       " 'ipsos*rasmussen': 0.0,\n",
       " 'ipsos*you_gov': 0.0,\n",
       " 'morning_consult*morning_consult': 0.0,\n",
       " 'morning_consult*rasmussen': 0.0,\n",
       " 'morning_consult*you_gov': 0.0,\n",
       " 'rasmussen*rasmussen': 0.0,\n",
       " 'rasmussen*you_gov': 0.0,\n",
       " 'you_gov*you_gov': 0.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform_one(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases, you might want to connect a step to multiple steps. For instance, you might to extract different kinds of features from a single input. An elegant way to do this is to use a `compose.TransformerUnion`. Essentially, the latter is a list of transformers who's results will be merged into a single `dict` when `transform_one` is called. As an example let's say that we want to apply a `feature_extraction.RBFSampler` as well as the `feature_extraction.PolynomialExtender`. This may be done as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-30T18:51:10.590963Z",
     "iopub.status.busy": "2021-08-30T18:51:10.586664Z",
     "iopub.status.idle": "2021-08-30T18:51:10.593356Z",
     "shell.execute_reply": "2021-08-30T18:51:10.593813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><div class=\"pipeline\"><details class=\"estimator\"><summary><pre class=\"estimator-name\">StandardScaler</pre></summary><code class=\"estimator-params\">\n",
       "{'counts': Counter(),\n",
       " 'means': defaultdict(&lt;class 'float'&gt;, {}),\n",
       " 'vars': defaultdict(&lt;class 'float'&gt;, {}),\n",
       " 'with_std': True}\n",
       "\n",
       "</code></details><div class=\"union\"><details class=\"estimator\"><summary><pre class=\"estimator-name\">PolynomialExtender</pre></summary><code class=\"estimator-params\">\n",
       "{'bias_name': 'bias',\n",
       " 'degree': 2,\n",
       " 'include_bias': False,\n",
       " 'interaction_only': False}\n",
       "\n",
       "</code></details><details class=\"estimator\"><summary><pre class=\"estimator-name\">RBFSampler</pre></summary><code class=\"estimator-params\">\n",
       "{'gamma': 1.0,\n",
       " 'n_components': 100,\n",
       " 'offsets': [5.206649942334032,\n",
       "             5.520860709807474,\n",
       "             5.285879545830004,\n",
       "             1.6331304674506673,\n",
       "             6.258784196252329,\n",
       "             4.123356869375632,\n",
       "             5.901103354780761,\n",
       "             1.978990465685782,\n",
       "             2.1342954887285606,\n",
       "             0.6279806299661728,\n",
       "             2.5267629720343514,\n",
       "             5.9624293329607285,\n",
       "             4.444261908413194,\n",
       "             0.03616443273443971,\n",
       "             5.006303925099419,\n",
       "             4.403868021989595,\n",
       "             5.6643720231499595,\n",
       "             3.6197640943995264,\n",
       "             0.4223746680116662,\n",
       "             1.3503244040990845,\n",
       "             5.480455304173762,\n",
       "             2.0801069510489816,\n",
       "             3.3853301945723975,\n",
       "             3.4909259915197794,\n",
       "             2.420445012764147,\n",
       "             2.65833222740381,\n",
       "             0.00046450448498994894,\n",
       "             3.7244104946413237,\n",
       "             3.0666225467258745,\n",
       "             4.177441331704589,\n",
       "             4.239269466936675,\n",
       "             6.1166309265821175,\n",
       "             3.4925271901552075,\n",
       "             2.711843714337492,\n",
       "             2.992728714120017,\n",
       "             1.0832121818138158,\n",
       "             2.399125836127348,\n",
       "             2.3939316348283413,\n",
       "             3.6621711822292844,\n",
       "             3.1432362773509617,\n",
       "             5.356574841731786,\n",
       "             3.64728299557865,\n",
       "             5.782835902349776,\n",
       "             4.712768962070241,\n",
       "             1.692600815175469,\n",
       "             4.6282195831263495,\n",
       "             2.2663610705270565,\n",
       "             4.978945453551218,\n",
       "             4.258602540267858,\n",
       "             6.01183773575003,\n",
       "             2.7842213309574357,\n",
       "             3.2119744482594217,\n",
       "             0.8238747902895948,\n",
       "             3.610761725607952,\n",
       "             5.950360616892287,\n",
       "             2.7137469747875063,\n",
       "             3.678478562405913,\n",
       "             2.6568035970266095,\n",
       "             1.119989248436358,\n",
       "             0.20369344974394132,\n",
       "             2.7696116647435955,\n",
       "             0.16980830850175566,\n",
       "             5.682795371467025,\n",
       "             3.61722314599064,\n",
       "             4.335713303908442,\n",
       "             2.377551156598251,\n",
       "             4.826908964734071,\n",
       "             0.8301352902691344,\n",
       "             2.3930522729119033,\n",
       "             0.4465210765796734,\n",
       "             1.9959383590315372,\n",
       "             2.2121769971331275,\n",
       "             2.784102085690305,\n",
       "             0.15763362458354058,\n",
       "             1.244975205460246,\n",
       "             3.390726494500028,\n",
       "             1.5663111859113756,\n",
       "             2.792115941275427,\n",
       "             5.934076902830572,\n",
       "             1.4136787951688052,\n",
       "             2.5572931116608904,\n",
       "             5.66947685580475,\n",
       "             5.844014489021741,\n",
       "             5.632700227013547,\n",
       "             2.073654425497519,\n",
       "             2.272224618175712,\n",
       "             5.161998499748893,\n",
       "             6.272114740104233,\n",
       "             3.814836643452376,\n",
       "             2.1279214346217548,\n",
       "             0.16274079831576221,\n",
       "             4.665697031126348,\n",
       "             6.159801919258009,\n",
       "             5.477483815351471,\n",
       "             0.4073534087195423,\n",
       "             0.24424470630844278,\n",
       "             0.6617934564545619,\n",
       "             4.156390335436172,\n",
       "             1.1368791294049534,\n",
       "             1.6895144329188274],\n",
       " 'rng': &lt;random.Random object at 0x5636f44e6f80&gt;,\n",
       " 'seed': None,\n",
       " 'weights': defaultdict(&lt;bound method RBFSampler._random_weights of RBFSampler (\n",
       "  gamma=1.\n",
       "  n_components=100\n",
       "  seed=None\n",
       ")&gt;, {})}\n",
       "\n",
       "</code></details></div><details class=\"estimator\"><summary><pre class=\"estimator-name\">LinearRegression</pre></summary><code class=\"estimator-params\">\n",
       "{'_weights': {},\n",
       " '_y_name': None,\n",
       " 'clip_gradient': 1000000000000.0,\n",
       " 'initializer': Zeros (),\n",
       " 'intercept': 0.0,\n",
       " 'intercept_init': 0.0,\n",
       " 'intercept_lr': Constant({'learning_rate': 0.01}),\n",
       " 'l2': 0.0,\n",
       " 'loss': Squared({}),\n",
       " 'optimizer': SGD({'lr': Constant({'learning_rate': 0.01}), 'n_iterations': 0})}\n",
       "\n",
       "</code></details></div></body><style>\n",
       ".estimator {\n",
       "    padding: 1em;\n",
       "    border-style: solid;\n",
       "    background: white;\n",
       "}\n",
       "\n",
       ".pipeline {\n",
       "    display: flex;\n",
       "    flex-direction: column;\n",
       "    align-items: center;\n",
       "    background: linear-gradient(#000, #000) no-repeat center / 3px 100%;\n",
       "}\n",
       "\n",
       ".union {\n",
       "    display: flex;\n",
       "    flex-direction: row;\n",
       "    align-items: center;\n",
       "    justify-content: center;\n",
       "    padding: 1em;\n",
       "    border-style: solid;\n",
       "    background: white\n",
       "}\n",
       "\n",
       "/* Vertical spacing between steps */\n",
       "\n",
       ".estimator + .estimator,\n",
       ".estimator + .union,\n",
       ".union + .estimator {\n",
       "    margin-top: 2em;\n",
       "}\n",
       "\n",
       ".union > .estimator {\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       "/* Spacing within a union of estimators */\n",
       "\n",
       ".union >\n",
       ".estimator + .estimator,\n",
       ".pipeline + .estimator,\n",
       ".estimator + .pipeline,\n",
       ".pipeline + .pipeline {\n",
       "    margin-left: 1em;\n",
       "}\n",
       "\n",
       "/* Typography */\n",
       ".estimator-params {\n",
       "    display: block;\n",
       "    white-space: pre-wrap;\n",
       "    font-size: 120%;\n",
       "    margin-bottom: -1em;\n",
       "}\n",
       "\n",
       ".estimator > code {\n",
       "    background-color: white !important;\n",
       "}\n",
       "\n",
       ".estimator-name {\n",
       "    display: inline;\n",
       "    margin: 0;\n",
       "    font-size: 130%;\n",
       "}\n",
       "\n",
       "/* Toggle */\n",
       "\n",
       "summary {\n",
       "    display: flex;\n",
       "    align-items:center;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       "summary > div {\n",
       "    width: 100%;\n",
       "}\n",
       "</style></html>"
      ],
      "text/plain": [
       "Pipeline (\n",
       "  StandardScaler (\n",
       "    with_std=True\n",
       "  ),\n",
       "  TransformerUnion (\n",
       "    PolynomialExtender (\n",
       "      degree=2\n",
       "      interaction_only=False\n",
       "      include_bias=False\n",
       "      bias_name=\"bias\"\n",
       "    ),\n",
       "    RBFSampler (\n",
       "      gamma=1.\n",
       "      n_components=100\n",
       "      seed=None\n",
       "    )\n",
       "  ),\n",
       "  LinearRegression (\n",
       "    optimizer=SGD (\n",
       "      lr=Constant (\n",
       "        learning_rate=0.01\n",
       "      )\n",
       "    )\n",
       "    loss=Squared ()\n",
       "    l2=0.\n",
       "    intercept_init=0.\n",
       "    intercept_lr=Constant (\n",
       "      learning_rate=0.01\n",
       "    )\n",
       "    clip_gradient=1e+12\n",
       "    initializer=Zeros ()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    (feature_extraction.PolynomialExtender() + feature_extraction.RBFSampler()) |\n",
    "    linear_model.LinearRegression()\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `+` symbol acts as a shorthand notation for creating a `compose.TransformerUnion`, which means that we could have declared the above pipeline as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-30T18:51:10.598951Z",
     "iopub.status.busy": "2021-08-30T18:51:10.597605Z",
     "iopub.status.idle": "2021-08-30T18:51:10.599564Z",
     "shell.execute_reply": "2021-08-30T18:51:10.600014Z"
    }
   },
   "outputs": [],
   "source": [
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    compose.TransformerUnion(\n",
    "        feature_extraction.PolynomialExtender(),\n",
    "        feature_extraction.RBFSampler()\n",
    "    ) |\n",
    "    linear_model.LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines provide the benefit of removing a lot of cruft by taking care of tedious details for you. They also enable to clearly define what steps your model is made of. Finally, having your model in a single object means that you can move it around more easily. Note that you can include user-defined functions in a pipeline by using a `compose.FuncTransformer`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
